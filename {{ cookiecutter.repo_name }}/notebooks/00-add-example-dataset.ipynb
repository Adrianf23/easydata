{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from functools import partial\n",
    "\n",
    "from {{ cookiecutter.module_name }}.data import datasets, utils, Dataset\n",
    "from {{ cookiecutter.module_name }}.data.datasets import (build_dataset_dict, fetch_and_unpack, fetch_text_file, read_space_delimited,\n",
    "                                   load_dataset)\n",
    "from {{ cookiecutter.module_name }}.data.utils import hash_file, list_dir, head_file, normalize_labels\n",
    "from {{ cookiecutter.module_name }}.paths import interim_data_path, raw_data_path, processed_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding and Processing Natural Datasets\n",
    "## The LVQ-PAK Finnish Phonetic dataset\n",
    "\n",
    "The Learning Vector Quantization project includes a simple Finnish phonetic dataset\n",
    "consisting 20-dimensional data and their associated targets. Let's explore this dataset and\n",
    "add it to our global `datasets.json` so it can be unpacked and processed automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name='lvq-pak'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the tarfile and build the dataset dictionary for it. If we know the hash of this file, we should include it here. If not, one will be computed from this download and used for comparison on subsequent downloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'http://www.cis.hut.fi/research/lvq_pak/lvq_pak-3.1.tar',\n",
       " 'hash_type': 'sha1',\n",
       " 'hash_value': '86024a871724e521341da0ffb783956e39aadb6e',\n",
       " 'name': None,\n",
       " 'file_name': None}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab the source code package\n",
    "lvq_pak = build_dataset_dict(url=\"http://www.cis.hut.fi/research/lvq_pak/lvq_pak-3.1.tar\")\n",
    "lvq_pak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **name** field can be used to indicate the type of datafile being downloaded. Usually, this is just informational. However, if you specify names `DESCR` or `LICENSE`, the downloaded (text) file will be used as the dataset description and license text, respectively.\n",
    "\n",
    "Usually you will want to give these unique names, so they don't clash with other downloaded files. (e.g. \"LICENSE.txt\" is a terrible name to use). We use the **file_name** option for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "descr = build_dataset_dict(url='http://www.cis.hut.fi/research/lvq_pak/README', file_name=f'{dataset_name}.readme',\n",
    "                       name='DESCR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.gitkeep', 'lvq-pak.license', 'lvq_pak-3.1.tar', 'lvq-pak.readme']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# notice the files have been downloaded to the RAW directory\n",
    "list_dir(raw_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we combine the complete set of files into a URL list and use this to build our json file entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'http://www.cis.hut.fi/research/lvq_pak/lvq_pak-3.1.tar',\n",
       "  'hash_type': 'sha1',\n",
       "  'hash_value': '86024a871724e521341da0ffb783956e39aadb6e',\n",
       "  'name': None,\n",
       "  'file_name': None},\n",
       " {'url': 'http://www.cis.hut.fi/research/lvq_pak/README',\n",
       "  'hash_type': 'sha1',\n",
       "  'hash_value': '138b69cc0b4e02950cec5833752e50a54d36fd0f',\n",
       "  'name': 'DESCR',\n",
       "  'file_name': 'lvq-pak.readme'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_list = [lvq_pak, descr]\n",
    "url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': 'fetch_and_process',\n",
      " 'load_function': functools.partial(<function new_dataset at 0x7f7c20955d90>, dataset_name='lvq-pak'),\n",
      " 'load_function_args': [],\n",
      " 'load_function_kwargs': {'dataset_name': 'lvq-pak'},\n",
      " 'load_function_module': '{{ cookiecutter.module_name }}.data.datasets',\n",
      " 'load_function_name': 'new_dataset',\n",
      " 'url_list': [{'file_name': None,\n",
      "               'hash_type': 'sha1',\n",
      "               'hash_value': '86024a871724e521341da0ffb783956e39aadb6e',\n",
      "               'name': None,\n",
      "               'url': 'http://www.cis.hut.fi/research/lvq_pak/lvq_pak-3.1.tar'},\n",
      "              {'file_name': 'lvq-pak.readme',\n",
      "               'hash_type': 'sha1',\n",
      "               'hash_value': '138b69cc0b4e02950cec5833752e50a54d36fd0f',\n",
      "               'name': 'DESCR',\n",
      "               'url': 'http://www.cis.hut.fi/research/lvq_pak/README'}]}\n"
     ]
    }
   ],
   "source": [
    "newds_dict = datasets.add_dataset_by_urllist(dataset_name, url_list)\n",
    "pprint(newds_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See that a generic `load_function` (`new_dataset`) has been used to process the data. This does nothing more than populates the DESCR and LICENSE fields (if possible), creating an otherwise empty `Dataset` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{{ cookiecutter.module_name }}.data.dset.Dataset"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, call the (generic) load function and notice that the LICENSE and DESCR have been set\n",
    "dset = newds_dict['load_function']()\n",
    "type(dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************\n",
      "*                                                                      *\n",
      "*                              LVQ_PAK                                 *\n",
      "*                                                                      *\n",
      "*                                The                                   *\n",
      "*                                                                      *\n",
      "*                   Learning  Vector  Quantization                     *\n",
      "*                                                                      *\n",
      "*                          Program  Package                            *\n",
      "*                                                                      *\n",
      "*                   Version 3.1 (April 7, 1995)                        *\n",
      "*                                                                      *\n",
      "*                          Prepared by the                             *\n",
      "*                    LVQ Programming Team of the                       *\n",
      "*                 Helsinki University of Technology                    *\n",
      "*           Laboratory of Computer and Information Science             *\n",
      "*                Rakentajanaukio 2 C, SF-02150 Espoo                   *\n",
      "*                              FINLAND                                 *\n",
      "*                                                                      *\n",
      "*                      Copyright (c) 1991-1995                         *\n",
      "*                                                                      *\n",
      "************************************************************************\n",
      "*                                                                      *\n",
      "*  NOTE: This program package is copyrighted in the sense that it      *\n",
      "*  may be used for scientific purposes. The package as a whole, or     *\n",
      "*  parts thereof, cannot be included or used in any commercial         *\n",
      "*  application without written permission granted by its producents.   *\n",
      "*  No programs contained in this package may be copied for commercial  *\n",
      "*  distribution.                                                       *\n",
      "*                                                                      *\n",
      "*  All comments concerning this program package may be sent to the     *\n",
      "*  e-mail address 'lvq@nucleus.hut.fi'.                                *\n",
      "*                                                                      *\n",
      "************************************************************************\n",
      "\n",
      "This package contains all the programs necessary for the correct\n",
      "application of certain LVQ (Learning Vector Quantization) algorithms\n",
      "in an arbitrary statistical classification or pattern recognition\n",
      "task.  To this package four options for the algorithms, the\n",
      "LVQ1, the LVQ2.1, the LVQ3 and the OLVQ1, have been selected.  \n",
      "\n",
      "In the implementation of the LVQ programs we have tried to use as\n",
      "simple a code as possible.  Therefore the programs are supposed to\n",
      "compile in various machines without any specific modifications made on\n",
      "the code.  All programs have been written in ANSI C.\n",
      "\n",
      "The lvq_pak program package includes the following files:\n",
      "  - Documentation:\n",
      "      README             this file\n",
      "      lvq_doc.ps         documentation in (c) PostScript format\n",
      "      lvq_doc.ps.Z       same as above but compressed\n",
      "      lvq_doc.txt        documentation in ASCII format\n",
      "  - Source file archives:\n",
      "      lvq_p3r1.exe       Self-extracting MS-DOS archive file\n",
      "      lvq_pak-3.1.tar    UNIX tape archive file\n",
      "      lvq_pak-3.1.tar.Z  same as above but compressed\n",
      "\n",
      "Installation in UNIX (in more detail, see lvq_doc.ps/txt):\n",
      "  - Uncompress lvq_pak-3.1.tar.Z\n",
      "  - Extract the files with \"tar xovf lvq_pak-3.1.tar\" which creates\n",
      "    the subdirectory lvq_pak-3.1\n",
      "  - Copy makefile.unix to the name makefile\n",
      "  - Revise switches in the makefile, if necessary\n",
      "  - Execute \"make\"\n",
      "\n",
      "Installation in MS-DOS (in more detail, see lvq_doc.ps/txt):\n",
      "  - By executing the command lvq_p3r1 the self-extracting archive\n",
      "    creates the directory lvq_pak.3r1 and extracts all the files in it\n",
      "  - You are supposed to use Borland C++ Version 3.1 and to have\n",
      "    all the necessary environment settings\n",
      "  - Copy the file makefile.dos to the name makefile\n",
      "  - Revise the compiler switches in the makefile, if necessary\n",
      "  - Execute \"make\"\n",
      "\n",
      "Revision history:\n",
      "  - Version 1.0 was released 19 December 1991.\n",
      "  - Version 1.1 containing only a minor bug fix in memory allocation\n",
      "    was released 31 December 1991.\n",
      "  - Version 2.0 containing major modifications in the algorithms was\n",
      "    released January 31, 1992.\n",
      "  - Version 2.1 containing some improvements in the speed of algorithms\n",
      "    and one new program was released October 9, 1992.\n",
      "  - Version 3.0 containing many advanced features conserning application\n",
      "    of the algorithms in large problems was released March 1, 1995; for\n",
      "    these changes see documentation.\n",
      "  - Version 3.1 containing only a bug fix in random ordering\n",
      "    was released 7 April 1995.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dset.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(dset.LICENSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets should *always* have an explicit license. Reading the project documentation, we see a license in one of the textfiles. We can extract and use that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "license_txt = '''\n",
    "************************************************************************\n",
    "*                                                                      *\n",
    "*                              LVQ_PAK                                 *\n",
    "*                                                                      *\n",
    "*                                The                                   *\n",
    "*                                                                      *\n",
    "*                   Learning  Vector  Quantization                     *\n",
    "*                                                                      *\n",
    "*                          Program  Package                            *\n",
    "*                                                                      *\n",
    "*                   Version 3.1 (April 7, 1995)                        *\n",
    "*                                                                      *\n",
    "*                          Prepared by the                             *\n",
    "*                    LVQ Programming Team of the                       *\n",
    "*                 Helsinki University of Technology                    *\n",
    "*           Laboratory of Computer and Information Science             *\n",
    "*                Rakentajanaukio 2 C, SF-02150 Espoo                   *\n",
    "*                              FINLAND                                 *\n",
    "*                                                                      *\n",
    "*                      Copyright (c) 1991-1995                         *\n",
    "*                                                                      *\n",
    "************************************************************************\n",
    "*                                                                      *\n",
    "*  NOTE: This program package is copyrighted in the sense that it      *\n",
    "*  may be used for scientific purposes. The package as a whole, or     *\n",
    "*  parts thereof, cannot be included or used in any commercial         *\n",
    "*  application without written permission granted by its producents.   *\n",
    "*  No programs contained in this package may be copied for commercial  *\n",
    "*  distribution.                                                       *\n",
    "*                                                                      *\n",
    "*  All comments concerning this program package may be sent to the     *\n",
    "*  e-mail address 'lvq@nucleus.hut.fi'.                                *\n",
    "*                                                                      *\n",
    "************************************************************************\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list += [datasets.build_dataset_dict(from_txt=license_txt, file_name=f'{dataset_name}.license', name='LICENSE')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, reload the dataset from scratch and check that the license is there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************************************************************************\n",
      "*                                                                      *\n",
      "*                              LVQ_PAK                                 *\n",
      "*                                                                      *\n",
      "*                                The                                   *\n",
      "*                                                                      *\n",
      "*                   Learning  Vector  Quantization                     *\n",
      "*                                                                      *\n",
      "*                          Program  Package                            *\n",
      "*                                                                      *\n",
      "*                   Version 3.1 (April 7, 1995)                        *\n",
      "*                                                                      *\n",
      "*                          Prepared by the                             *\n",
      "*                    LVQ Programming Team of the                       *\n",
      "*                 Helsinki University of Technology                    *\n",
      "*           Laboratory of Computer and Information Science             *\n",
      "*                Rakentajanaukio 2 C, SF-02150 Espoo                   *\n",
      "*                              FINLAND                                 *\n",
      "*                                                                      *\n",
      "*                      Copyright (c) 1991-1995                         *\n",
      "*                                                                      *\n",
      "************************************************************************\n",
      "*                                                                      *\n",
      "*  NOTE: This program package is copyrighted in the sense that it      *\n",
      "*  may be used for scientific purposes. The package as a whole, or     *\n",
      "*  parts thereof, cannot be included or used in any commercial         *\n",
      "*  application without written permission granted by its producents.   *\n",
      "*  No programs contained in this package may be copied for commercial  *\n",
      "*  distribution.                                                       *\n",
      "*                                                                      *\n",
      "*  All comments concerning this program package may be sent to the     *\n",
      "*  e-mail address 'lvq@nucleus.hut.fi'.                                *\n",
      "*                                                                      *\n",
      "************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newds_dict = datasets.add_dataset_by_urllist(dataset_name, url_list)\n",
    "dset = datasets.load_dataset(dataset_name)\n",
    "print(dset.LICENSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the data\n",
    "The next step is to write the importer that actually processes the data we will be using for this dataset.\n",
    "\n",
    "The important things to generate are `data` and `target` entries. A `metadata` is optional, but recommended if you want to save additional information about the dataset.\n",
    "\n",
    "Usually, this functionality gets bundled up into a function and added to `datasets.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['balance.c',\n",
       " 'config.h',\n",
       " 'lvq_rout.c',\n",
       " 'ex1.dat',\n",
       " 'knntest.c',\n",
       " 'classify.c',\n",
       " 'README',\n",
       " 'fileio.h',\n",
       " 'mindist.c',\n",
       " 'lvq_pak.h',\n",
       " 'labels.c',\n",
       " 'pick.c',\n",
       " 'lvq_run.c',\n",
       " 'ex2.dat',\n",
       " 'lvqtrain.c',\n",
       " 'accuracy.c',\n",
       " 'datafile.c',\n",
       " 'cmatr.c',\n",
       " 'fileio.c',\n",
       " 'makefile.dos',\n",
       " 'VERSION',\n",
       " 'version.h',\n",
       " 'mcnemar.c',\n",
       " 'sammon.c',\n",
       " 'stddev.c',\n",
       " 'elimin.c',\n",
       " 'lvq_pak.c',\n",
       " 'lvq_rout.h',\n",
       " 'showlabs.c',\n",
       " 'extract.c',\n",
       " 'setlabel.c',\n",
       " 'labels.h',\n",
       " 'version.c',\n",
       " 'datafile.h',\n",
       " 'makefile.unix',\n",
       " 'eveninit.c',\n",
       " 'errors.h']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpack the file\n",
    "untar_dir = fetch_and_unpack(dataset_name)\n",
    "unpack_dir = untar_dir / 'lvq_pak-3.1'\n",
    "list_dir(unpack_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset, the training and test datsets are stored in files named `ex1.dat` and `ex2.dat` respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafile_train = unpack_dir / 'ex1.dat'\n",
    "datafile_test = unpack_dir / 'ex2.dat'\n",
    "\n",
    "datafile_train.exists() and datafile_test.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the documentation, the data format is space-delimited, with the class label included as the last column. Let's have a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "# Example data from speech signal\n",
      "21.47 -19.90 -20.68 -6.73 13.67 -11.95 13.83 12.02 7.62 -6.15 -4.38 -2.91 4.80 -7.39 -3.54 -0.87 -5.02 -1.41 -2.33 2.12 A\n",
      "0.05 28.38 9.52 -11.30 3.11 -11.88 -2.90 -11.04 2.32 -13.80 1.71 -0.40 -1.36 3.91 3.21 -0.98 -0.14 -4.70 0.30 0.27 I\n",
      "-4.71 -4.61 -0.64 1.78 -1.48 5.98 12.55 -0.50 4.74 4.68 3.27 -0.36 9.24 3.39 -0.40 -1.59 0.94 2.17 -0.10 -0.45 #\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(head_file(datafile_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, the datafile consists of 1 line containing the dimension of the data, a comment, and then 21 space-delimited columns, the final column being the target class label. \n",
    "\n",
    "**Note:** We have to be a little careful importing the data, because '#' is used both as the comment delimiter, and as a class label.\n",
    "\n",
    "Fortunately, we have a helper function for this. We will get a little cheeky and skip the first 2 lines (hoping there are no other comments). The documentation also says ther are 1962 entries in each of the training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1962, 20), (1962,), (1962, 20), (1962,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, target = read_space_delimited(datafile_train, skiprows=[0,1])\n",
    "data2, target2 = read_space_delimited(datafile_test, skiprows=[0])\n",
    "\n",
    "data.shape, target.shape, data2.shape, target2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'I', '#', ..., '#', 'Y', '#'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to work, so let's wrap this functionality up into a processing function.\n",
    "By convention, the function takes a `dataset_name`, and any other options that may be useful for reading the data, and returns a dictionary that matches the `Dataset` constructor signature.\n",
    "\n",
    "We will place this function in `localdata.py`, (and add it to `__all__`) to make it visible to our dataset code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/data/localdata.py\n"
     ]
    }
   ],
   "source": [
    "%%file ../src/data/localdata.py\n",
    "\"\"\"\n",
    "Custom dataset processing/generation functions should be added to this file\n",
    "\"\"\"\n",
    "\n",
    "from {{ cookiecutter.module_name }}.data.utils import read_space_delimited, normalize_labels\n",
    "from {{ cookiecutter.module_name }}.paths import interim_data_path\n",
    "import numpy as np\n",
    "\n",
    "__all__ = ['process_lvq_pak']\n",
    "\n",
    "def process_lvq_pak(dataset_name='lvq-pak', kind='all', numeric_labels=True, metadata=None):\n",
    "    \"\"\"\n",
    "    kind: {'test', 'train', 'all'}, default 'all'\n",
    "    numeric_labels: boolean (default: True)\n",
    "        if set, target is a vector of integers, and label_map is created in the metadata\n",
    "        to reflect the mapping to the string targets\n",
    "    \"\"\"\n",
    "    \n",
    "    untar_dir = interim_data_path / dataset_name\n",
    "    unpack_dir = untar_dir / 'lvq_pak-3.1'\n",
    "\n",
    "    if kind == 'train':\n",
    "        data, target = read_space_delimited(unpack_dir / 'ex1.dat', skiprows=[0,1])\n",
    "    elif kind == 'test':\n",
    "        data, target = read_space_delimited(unpack_dir / 'ex2.dat', skiprows=[0])\n",
    "    elif kind == 'all':\n",
    "        data1, target1 = read_space_delimited(unpack_dir / 'ex1.dat', skiprows=[0,1])\n",
    "        data2, target2 = read_space_delimited(unpack_dir / 'ex2.dat', skiprows=[0])\n",
    "        data = np.vstack((data1, data2))\n",
    "        target = np.append(target1, target2)\n",
    "    else:\n",
    "        raise Exception(f'Unknown kind: {kind}')\n",
    "\n",
    "    if numeric_labels:\n",
    "        if metadata is None:\n",
    "            metadata = {}\n",
    "        mapped_target, label_map = normalize_labels(target)\n",
    "        metadata['label_map'] = label_map\n",
    "        target = mapped_target\n",
    "\n",
    "    dset_opts = {\n",
    "        'dataset_name': dataset_name,\n",
    "        'data': data,\n",
    "        'target': target,\n",
    "        'metadata': metadata\n",
    "    }\n",
    "    return dset_opts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure this works as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: data=(1962, 20) target=(1962,)\n",
      "test: data=(1962, 20) target=(1962,)\n",
      "all: data=(3924, 20) target=(3924,)\n"
     ]
    }
   ],
   "source": [
    "from {{ cookiecutter.module_name }}.data.localdata import process_lvq_pak\n",
    "\n",
    "for kind in ['train', 'test', 'all']:\n",
    "    dset_opts = process_lvq_pak(kind=kind)\n",
    "    dset = Dataset(**dset_opts)\n",
    "    print(f'{kind}: data={dset.data.shape} target={dset.target.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This all looks good\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action': 'fetch_and_process',\n",
       " 'load_function_args': [],\n",
       " 'load_function_kwargs': {},\n",
       " 'load_function_module': '{{ cookiecutter.module_name }}.data.localdata',\n",
       " 'load_function_name': 'process_lvq_pak',\n",
       " 'url_list': [{'file_name': None,\n",
       "   'hash_type': 'sha1',\n",
       "   'hash_value': '86024a871724e521341da0ffb783956e39aadb6e',\n",
       "   'name': None,\n",
       "   'url': 'http://www.cis.hut.fi/research/lvq_pak/lvq_pak-3.1.tar'},\n",
       "  {'file_name': 'lvq-pak.readme',\n",
       "   'hash_type': 'sha1',\n",
       "   'hash_value': '138b69cc0b4e02950cec5833752e50a54d36fd0f',\n",
       "   'name': 'DESCR',\n",
       "   'url': 'http://www.cis.hut.fi/research/lvq_pak/README'},\n",
       "  {'contents': \"\\n************************************************************************\\n*                                                                      *\\n*                              LVQ_PAK                                 *\\n*                                                                      *\\n*                                The                                   *\\n*                                                                      *\\n*                   Learning  Vector  Quantization                     *\\n*                                                                      *\\n*                          Program  Package                            *\\n*                                                                      *\\n*                   Version 3.1 (April 7, 1995)                        *\\n*                                                                      *\\n*                          Prepared by the                             *\\n*                    LVQ Programming Team of the                       *\\n*                 Helsinki University of Technology                    *\\n*           Laboratory of Computer and Information Science             *\\n*                Rakentajanaukio 2 C, SF-02150 Espoo                   *\\n*                              FINLAND                                 *\\n*                                                                      *\\n*                      Copyright (c) 1991-1995                         *\\n*                                                                      *\\n************************************************************************\\n*                                                                      *\\n*  NOTE: This program package is copyrighted in the sense that it      *\\n*  may be used for scientific purposes. The package as a whole, or     *\\n*  parts thereof, cannot be included or used in any commercial         *\\n*  application without written permission granted by its producents.   *\\n*  No programs contained in this package may be copied for commercial  *\\n*  distribution.                                                       *\\n*                                                                      *\\n*  All comments concerning this program package may be sent to the     *\\n*  e-mail address 'lvq@nucleus.hut.fi'.                                *\\n*                                                                      *\\n************************************************************************\\n\",\n",
       "   'file_name': 'lvq-pak.license',\n",
       "   'hash_type': 'sha1',\n",
       "   'hash_value': 'e5f53b172926d34cb6a49877be49ee08bc4d51c1',\n",
       "   'name': 'LICENSE'}],\n",
       " 'load_function': functools.partial(<function process_lvq_pak at 0x7f7c20985a60>)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.add_dataset_from_function(dataset_name, process_lvq_pak)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, re-load the dataset and save a copy of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:(3924, 20), target:(3924,)\n"
     ]
    }
   ],
   "source": [
    "lvq = load_dataset(dataset_name)\n",
    "print(f\"data:{lvq.data.shape}, target:{lvq.target.shape}\")\n",
    "lvq.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metadata': {'label_map': {0: '#',\n",
       "   1: '&',\n",
       "   2: 'A',\n",
       "   3: 'D',\n",
       "   4: 'E',\n",
       "   5: 'F',\n",
       "   6: 'H',\n",
       "   7: 'I',\n",
       "   8: 'J',\n",
       "   9: 'L',\n",
       "   10: 'M',\n",
       "   11: 'N',\n",
       "   12: 'O',\n",
       "   13: 'R',\n",
       "   14: 'S',\n",
       "   15: 'U',\n",
       "   16: 'V',\n",
       "   17: 'Y',\n",
       "   18: '[',\n",
       "   19: '\\\\'},\n",
       "  'dataset_name': 'lvq-pak',\n",
       "  'data_hash': 'c87a90aee1ddadb50282e68b9f0155a74b6d7a61',\n",
       "  'target_hash': '6332a9bca3d44ccf311a79013a4e3937abe12be5'},\n",
       " 'data': array([['21.47', '-19.90', '-20.68', ..., '-1.41', '-2.33', '2.12'],\n",
       "        ['0.05', '28.38', '9.52', ..., '-4.70', '0.30', '0.27'],\n",
       "        ['-4.71', '-4.61', '-0.64', ..., '2.17', '-0.10', '-0.45'],\n",
       "        ...,\n",
       "        ['-2.63', '-6.59', '0.19', ..., '0.76', '0.89', '-3.48'],\n",
       "        ['5.35', '4.96', '18.75', ..., '-0.57', '0.00', '1.35'],\n",
       "        ['-0.37', '-5.27', '-1.74', ..., '3.48', '-0.90', '-1.00']],\n",
       "       dtype=object),\n",
       " 'target': array([ 2,  7,  0, ...,  0, 17,  0])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lvq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.gitkeep', 'lvq-pak.dataset', 'lvq-pak.metadata']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_dir(processed_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_hash': 'c87a90aee1ddadb50282e68b9f0155a74b6d7a61',\n",
      " 'dataset_name': 'lvq-pak',\n",
      " 'label_map': {0: '#',\n",
      "               1: '&',\n",
      "               2: 'A',\n",
      "               3: 'D',\n",
      "               4: 'E',\n",
      "               5: 'F',\n",
      "               6: 'H',\n",
      "               7: 'I',\n",
      "               8: 'J',\n",
      "               9: 'L',\n",
      "               10: 'M',\n",
      "               11: 'N',\n",
      "               12: 'O',\n",
      "               13: 'R',\n",
      "               14: 'S',\n",
      "               15: 'U',\n",
      "               16: 'V',\n",
      "               17: 'Y',\n",
      "               18: '[',\n",
      "               19: '\\\\'},\n",
      " 'target_hash': '6332a9bca3d44ccf311a79013a4e3937abe12be5'}\n"
     ]
    }
   ],
   "source": [
    "pprint(lvq.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
